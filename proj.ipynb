{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93e97ad",
   "metadata": {},
   "source": [
    "# Objective 1: Predict Death "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a5c4e",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "data = pd.read_csv('data/custom_covid19.csv') \n",
    "print(\"Data loaded with shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159f494",
   "metadata": {},
   "source": [
    "##### 1. Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a401ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DIED'] = data['DATE_DIED'].apply(lambda x: 0 if x == '9999-99-99' else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01577827",
   "metadata": {},
   "source": [
    "##### 2. Mark missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a677a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([97, 98, 99], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38857dd",
   "metadata": {},
   "source": [
    "##### 3. Convert boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = ['INTUBED', 'PNEUMONIA', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', \n",
    "             'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', \n",
    "             'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU']\n",
    "data[bool_cols] = data[bool_cols].replace(2, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f08925",
   "metadata": {},
   "source": [
    "##### 4. Create COVID status feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda834cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['COVID_POSITIVE'] = data['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bb1ab",
   "metadata": {},
   "source": [
    "##### 5. Define features to keep/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', \n",
    "                   'INTUBED', 'PNEUMONIA', 'AGE', 'DIABETES', 'COPD',\n",
    "                   'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE',\n",
    "                   'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO',\n",
    "                   'ICU', 'COVID_POSITIVE']\n",
    "\n",
    "# 6. Separate features and target\n",
    "X = data[features_to_keep]\n",
    "y = data['DIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143b8bb",
   "metadata": {},
   "source": [
    "##### 6. Define preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced from 18173 to 18173 rows.\n",
      "Numeric features: ['AGE']\n",
      "Categorical features: ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'INTUBED', 'PNEUMONIA', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['AGE']\n",
    "categorical_features = [col for col in features_to_keep \n",
    "                       if col not in numeric_features + ['DIED', 'COVID_POSITIVE']]\n",
    "\n",
    "data = data.dropna()  # Drops all rows with any NaN\n",
    "print(f\"Data reduced from {len(data)} to {len(data.dropna())} rows.\")\n",
    "\n",
    "# # Numeric pipeline (mean imputation + scaling)\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Categorical pipeline (mode imputation)\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "# ])\n",
    "\n",
    "# Combined preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num',  numeric_features),\n",
    "    ('cat', categorical_features)\n",
    "])\n",
    "\n",
    "# numeric_transformer,\n",
    "# categorical_transformer,\n",
    "\n",
    "# Verification\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293cb08",
   "metadata": {},
   "source": [
    "##### 8. Train-test split\n",
    " \n",
    "Split the data into training and testing sets\n",
    "Stratified split to maintain the same distribution of the target variable in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e62d2b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (80000, 19), Test set: (20000, 19)\n",
      "Class distribution (train): DIED\n",
      "0    0.926625\n",
      "1    0.073375\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution (train): {pd.Series(y_train).value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f8b9c",
   "metadata": {},
   "source": [
    "##### 9. Model Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fcfd7e",
   "metadata": {},
   "source": [
    "1. Model Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8d12708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll evaluate three baseline classifiers:\n",
    "# 1. Naive Bayes (probabilistic)\n",
    "# 2. K-Nearest Neighbors (instance-based)\n",
    "# 3. SVM with RBF kernel (maximum margin)\n",
    "\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "sns.set_palette(\"husl\")\n",
    "# Ensure 'figures' directory exists\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae8afd",
   "metadata": {},
   "source": [
    "2. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model and generates report-ready outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - name: str, model name for display\n",
    "    - model: sklearn classifier object\n",
    "    - X_train, X_test, y_train, y_test: training/test data\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing metrics and visualization paths\n",
    "    \"\"\"\n",
    "    # Create pipeline and fit model\n",
    "    clf = make_pipeline(preprocessor, model)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Create classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Confusion matrix heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Survived', 'Died'],\n",
    "                yticklabels=['Survived', 'Died'])\n",
    "    ax1.set_title(f'{name} Confusion Matrix')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('Actual')\n",
    "\n",
    "    # Metrics bar plot\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    scores = [report['weighted avg'][m] for m in metrics]\n",
    "    sns.barplot(x=metrics, y=scores, ax=ax2)\n",
    "    ax2.set_title(f'{name} Performance Metrics')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # Save the figure\n",
    "    fig_path = f'figures/{name.lower().replace(\" \", \"_\")}_performance.png'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Display outputs in the notebook\n",
    "    display(Markdown(f\"## {name} Performance\"))\n",
    "    display(Markdown(\"### Classification Report\"))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    display(Markdown(\"### Confusion Matrix\"))\n",
    "    print(cm)\n",
    "\n",
    "    return {\n",
    "        'model': name,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1': report['weighted avg']['f1-score'],\n",
    "        'figure_path': fig_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5aa60",
   "metadata": {},
   "source": [
    "3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Baseline Model Definitions\n",
    "# We select three distinct algorithmic approaches:\n",
    "\n",
    "models = [\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('Support Vector Machine', LinearSVC(random_state=42, class_weight='balanced'))  # Updated\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0ea17",
   "metadata": {},
   "source": [
    "4. Model Evaluation Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate All Baseline Models ===\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for name, model in models:\n",
    "    result = evaluate_model(name, model, X_train, X_test, y_train, y_test)\n",
    "    model_results.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8706e",
   "metadata": {},
   "source": [
    "##### 10. Hyperparameter Optimization\n",
    "We implement systematic hyperparameter tuning for all three models using GridSearchCV (exhaustive search) to find optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeef901",
   "metadata": {},
   "source": [
    "A. Naive Bayes (GaussianNB)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9124c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7]  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5cab2",
   "metadata": {},
   "source": [
    "B. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__p': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec82ea",
   "metadata": {},
   "source": [
    "C. Support Vector Machine (SVM) //TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2eaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid_svm = {\n",
    "#     'svc__C': [0.1, 1, 10],\n",
    "#     'svc__gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "#     'svc__kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svc__C': [1, 10],             # instead of a wider range\n",
    "#     'svc__gamma': [0.1, 0.01],     # fewer values\n",
    "#     'svc__kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svc__base_estimator__C': [0.1, 1, 10],  \n",
    "#     'svc__base_estimator__max_iter': [1000, 2000]  \n",
    "# }\n",
    "\n",
    "param_grid_svm = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10]  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2be46",
   "metadata": {},
   "source": [
    "##### 11. Implementation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57551403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Create pipelines with preprocessing + model\n",
    "pipeline_nb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gaussiannb', GaussianNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('kneighborsclassifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', LinearSVC(random_state=42, class_weight='balanced'))  # Handles imbalance\n",
    "])\n",
    "\n",
    "# pipeline_svm = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('svc', SVC(probability=True, random_state=42))\n",
    "# ])\n",
    "\n",
    "# GridSearchCV setup with comprehensive parameter grids\n",
    "grid_nb = GridSearchCV(\n",
    "    pipeline_nb, \n",
    "    param_grid_nb, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    pipeline_knn, \n",
    "    param_grid_knn, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm, \n",
    "    param_grid_svm, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit models with timing\n",
    "import time\n",
    "\n",
    "print(\"Optimizing Naive Bayes...\")\n",
    "start = time.time()\n",
    "grid_nb.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "print(\"Optimizing KNN...\")\n",
    "start = time.time()\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "print(\"Optimizing Linear SVC...\")\n",
    "start = time.time()\n",
    "grid_svm.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Naive Bayes best params:\", grid_nb.best_params_)\n",
    "print(\"KNN best params:\", grid_knn.best_params_)\n",
    "print(\"Linear SVC best params:\", grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dd932",
   "metadata": {},
   "source": [
    "##### 12. Valuation using DecisionTree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pipeline_tree = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('decisiontreeclassifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Expanded parameter grid for more thorough search\n",
    "param_grid_tree = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "    'decisiontreeclassifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(\n",
    "    pipeline_tree, \n",
    "    param_grid_tree, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Optimizing Decision Tree...\")\n",
    "start = time.time()\n",
    "grid_tree.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"=== Decision Tree Performance ===\")\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tree, target_names=[\"Alive\", \"Died\"]))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred_tree)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Alive\", \"Died\"],\n",
    "            yticklabels=[\"Alive\", \"Died\"])\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d7bf9",
   "metadata": {},
   "source": [
    "##### 13. Benchmark Models with Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1302aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Model Evaluation Function\n",
    "def evaluate_model(grid, name, X_test, y_test):\n",
    "    y_pred = grid.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Best Params': str(grid.best_params_),\n",
    "        'Train F1': grid.best_score_,\n",
    "        'Test F1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'Test Accuracy': report['accuracy'],\n",
    "        'Test Precision': report['weighted avg']['precision'],\n",
    "        'Test Recall': report['weighted avg']['recall']\n",
    "    }\n",
    "\n",
    "# 2. Evaluate All Models\n",
    "results = [\n",
    "    evaluate_model(grid_nb, \"Naive Bayes\", X_test, y_test),\n",
    "    evaluate_model(grid_knn, \"KNN\", X_test, y_test),\n",
    "    evaluate_model(grid_svm, \"Linear SVC\", X_test, y_test),\n",
    "    evaluate_model(grid_tree, \"Decision Tree\", X_test, y_test)\n",
    "]\n",
    "\n",
    "# 3. Results Comparison\n",
    "results_df = pd.DataFrame(results).sort_values('Test F1', ascending=False)\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "display(results_df.style.background_gradient(cmap='Blues', subset=['Test F1', 'Test Accuracy']))\n",
    "\n",
    "# 4. Feature Importance Analysis (for Tree-based Models)\n",
    "if 'Decision Tree' in results_df['Model'].values:\n",
    "    # Get the trained model and preprocessor\n",
    "    best_tree = grid_tree.best_estimator_.named_steps['decisiontreeclassifier']\n",
    "    \n",
    "    # Get original feature names (before any transformations)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Verify lengths match\n",
    "    if len(feature_names) != len(best_tree.feature_importances_):\n",
    "        print(f\"Warning: Feature count mismatch ({len(feature_names)} vs {len(best_tree.feature_importances_)})\")\n",
    "        feature_names = [f'feature_{i}' for i in range(len(best_tree.feature_importances_))]\n",
    "\n",
    "    # Extract feature names after preprocessing\n",
    "    num_features = numeric_features  # list of numerical feature names\n",
    "    cat_features = categorical_features  # use the original categorical feature names\n",
    "    feature_names = list(num_features) + list(cat_features)\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': best_tree.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Visualize top 10 features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
    "    plt.title('Top 10 Predictive Features for Mortality', fontsize=14)\n",
    "    plt.xlabel('Relative Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation of Key Features\n",
    "    print(\"\\n=== Key Findings from Feature Importance ===\")\n",
    "    print(\"1. PATIENT_TYPE (hospitalization status) is the strongest predictor\")\n",
    "    print(\"2. AGE is the second most important factor\")\n",
    "    print(\"3. INTUBED (ventilator use) and PNEUMONIA are critical clinical indicators\")\n",
    "    print(\"4. Other chronic conditions show relatively small but meaningful impact\")\n",
    "    \n",
    "    # Display full importance table\n",
    "    print(\"\\n=== Complete Feature Importance ===\")\n",
    "    display(importance_df.style.background_gradient(cmap='Blues', subset=['Importance']))\n",
    "\n",
    "# 5. Confusion Matrix for Best Model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = {\n",
    "    \"Naive Bayes\": grid_nb,\n",
    "    \"KNN\": grid_knn,\n",
    "    \"Linear SVC\": grid_svm,\n",
    "    \"Decision Tree\": grid_tree\n",
    "}[best_model_name]\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',\n",
    "            xticklabels=['Survived', 'Died'],\n",
    "            yticklabels=['Survived', 'Died'])\n",
    "plt.title(f'{best_model_name} - Confusion Matrix', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 6. Final Model Selection\n",
    "print(f\"\\n=== Best Performing Model: {best_model_name} ===\")\n",
    "print(\"Considerations for model selection:\")\n",
    "print(\"- Clinical interpretability of decision trees\")\n",
    "print(\"- Importance of understanding feature relationships\")\n",
    "print(\"- Good balance between performance and complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8cfe1",
   "metadata": {},
   "source": [
    "# Objective 2 (O2): Age Prediction\n",
    "**Goal**: Predict the AGE of subjects given other attributes  \n",
    "**Approach**:  \n",
    "- Treat as a regression problem  \n",
    "- Evaluate different regression models  \n",
    "- Optimize hyperparameters  \n",
    "- Analyze feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bf03f",
   "metadata": {},
   "source": [
    "\n",
    "Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1caffa4",
   "metadata": {},
   "source": [
    "##### 1. Prepare Data for Age Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['AGE'].notna()].copy()  # Drop rows with missing AGE\n",
    "\n",
    "# We'll use the same preprocessing pipeline but change the target to AGE\n",
    "features_to_keep = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', \n",
    "                   'INTUBED', 'PNEUMONIA', 'DIABETES', 'COPD',\n",
    "                   'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE',\n",
    "                   'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO',\n",
    "                   'ICU', 'COVID_POSITIVE']\n",
    "\n",
    "X_age = data[features_to_keep]\n",
    "y_age = data['AGE']  # Target is now AGE\n",
    "\n",
    "# Train-test split\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(\n",
    "    X_age, y_age, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab694c43",
   "metadata": {},
   "source": [
    "\n",
    "##### 2. Define Preprocessing Pipeline\n",
    "Similar to O1 but adapted for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "numeric_features_age = []  # No numeric features besides AGE (our target)\n",
    "# if binari Covid\n",
    "# numeric_features_age = ['COVID_POSITIVE']\n",
    "# categorical_features_age = [col for col in features_to_keep if col not in numeric_features_age]\n",
    "categorical_features_age = [col for col in features_to_keep if col != 'COVID_POSITIVE']\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer_age = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer_age = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "preprocessor_age = ColumnTransformer([\n",
    "    ('num', numeric_transformer_age, numeric_features_age),\n",
    "    ('cat', categorical_transformer_age, categorical_features_age)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cf7f6",
   "metadata": {},
   "source": [
    "##### 3. Baseline Regression Mode\n",
    "\n",
    "Let's test three different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to evaluate\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "models_age = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "    #('Support Vector Regression', SVR())\n",
    "    ##Lasso Regression, Ridge Regression, ElasticNet\n",
    "    ('Lasso Regression', Lasso()),\n",
    "]\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models_age:\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor_age),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit and predict\n",
    "    pipeline.fit(X_train_age, y_train_age)\n",
    "    y_pred = pipeline.predict(X_test_age)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test_age, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_age, y_pred))\n",
    "    r2 = r2_score(y_test_age, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33126945",
   "metadata": {},
   "source": [
    "##### 4. Hyperparameter Optimization for Best Model\n",
    "\n",
    "Based on initial results, let's optimize RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad66bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline for optimization\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor_age),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_rf = GridSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Random Forest optimization...\")\n",
    "grid_rf.fit(X_train_age, y_train_age)\n",
    "print(\"Optimization completed!\")\n",
    "\n",
    "# Show best parameters\n",
    "print(\"\\nBest parameters:\", grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774dee5",
   "metadata": {},
   "source": [
    "##### 5. Evaluate Optimized Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861341f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = best_rf.predict(X_test_age)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test_age, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_age, y_pred_rf))\n",
    "r2 = r2_score(y_test_age, y_pred_rf)\n",
    "\n",
    "print(\"\\n=== Optimized Random Forest ===\")\n",
    "print(f\"MAE: {mae:.2f} years\")\n",
    "print(f\"RMSE: {rmse:.2f} years\")\n",
    "print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_age, y_pred_rf, alpha=0.3)\n",
    "plt.plot([y_test_age.min(), y_test_age.max()], \n",
    "         [y_test_age.min(), y_test_age.max()], 'r--')\n",
    "plt.xlabel('Actual Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.title('Actual vs Predicted Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701a28b",
   "metadata": {},
   "source": [
    "##### 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "# Get feature importances\n",
    "if hasattr(best_rf.named_steps['regressor'], 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = categorical_features_age  # Should match the number of importances\n",
    "    \n",
    "    importances = best_rf.named_steps['regressor'].feature_importances_\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title('Feature Importance for Age Prediction')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 5 Features Predicting Age:\")\n",
    "    display(importance_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a35588",
   "metadata": {},
   "source": [
    "##### 7. Final Model Selection and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf, 'best_age_predictor.pkl')\n",
    "print(\"Best age prediction model saved as 'best_age_predictor.pkl'\")\n",
    "# Load the model\n",
    "loaded_model = joblib.load('best_age_predictor.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c5d9e",
   "metadata": {},
   "source": [
    "### Conclusion for O2\n",
    "**Key Findings**:\n",
    "- Best model: Random Forest with MAE of 11.25 years\n",
    "- Most important features: Hypertension, Diabities\n",
    "- R2 score of 27% indicates moderate explanatory power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92faa128",
   "metadata": {},
   "source": [
    "# Objective 3 (O3): Predicting Age of Deceased Patients by COVID Status\n",
    "\n",
    "In this section, we aim to predict the **age at death** for individuals who died, separately for those with and without COVID-19. \n",
    "\n",
    "We train two regression models:\n",
    "- One for **COVID-positive deceased patients**\n",
    "- One for **COVID-negative deceased patients**\n",
    "\n",
    "This allows us to analyze how well we can estimate age at death using available features and whether COVID status impacts this predictability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9524be",
   "metadata": {},
   "source": [
    "#### 1. Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for deceased individuals\n",
    "deceased = data[data['DIED'] == 1].copy()\n",
    "print(f\"Number of deceased patients: {deceased.shape[0]}\")\n",
    "\n",
    "# Separate COVID-positive and COVID-negative deceased individuals\n",
    "deceased_covid_pos = deceased[deceased['COVID_POSITIVE'] == 1].copy()\n",
    "deceased_covid_neg = deceased[deceased['COVID_POSITIVE'] == 0].copy()\n",
    "\n",
    "print(f\"Deceased COVID-positive patients: {deceased_covid_pos.shape[0]}\")\n",
    "print(f\"Deceased COVID-negative patients: {deceased_covid_neg.shape[0]}\")\n",
    "\n",
    "# Define features (same as O2)\n",
    "features_for_age_prediction = [col for col in deceased.columns if col not in ['AGE', 'DIED']]\n",
    "# Remove string features that can't be encoded directly (e.g., dates)\n",
    "non_numeric_cols = deceased[features_for_age_prediction].select_dtypes(include='object').columns\n",
    "print(f\"Excluding non-numeric columns: {list(non_numeric_cols)}\")\n",
    "\n",
    "features_for_age_prediction = [col for col in features_for_age_prediction if col not in non_numeric_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a315a9",
   "metadata": {},
   "source": [
    "#### 2. Implementation Steps\n",
    "For COVID-positive deceased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7309d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y) for each group\n",
    "X_pos = deceased[features_for_age_prediction]\n",
    "y_pos = deceased['AGE']\n",
    "# print(X_pos.dtypes)\n",
    "print(f\"Features for COVID-positive deceased: {X_pos.shape[1]} features\")\n",
    "# print(y_pos.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a075d70",
   "metadata": {},
   "source": [
    "For COVID-negative deceased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's properly clean the parameters from grid_rf\n",
    "best_params = grid_rf.best_params_\n",
    "clean_params = {k.replace('regressor__', ''): v for k, v in best_params.items()}\n",
    "\n",
    "# For COVID-negative deceased patients\n",
    "X_neg = deceased[features_for_age_prediction]\n",
    "y_neg = deceased['AGE']\n",
    "print(f\"Features for COVID-negative deceased: {X_neg.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b1958",
   "metadata": {},
   "source": [
    "#### 3. Define Preprocessing Pipeline for Regression (preprocessor_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723beca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression, 'AGE' is the target, so it's not a feature in this preprocessor.\n",
    "# All other features are treated as categorical/boolean for this specific setup.\n",
    "numerical_features_reg = [] # No numerical features left to be scaled by StandardScaler apart from AGE\n",
    "categorical_features_reg = features_for_age_prediction\n",
    "\n",
    "# Define the transformers for the preprocessing pipeline\n",
    "numeric_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "    # If you later decide to OneHotEncode specific categorical features (e.g., MEDICAL_UNIT)\n",
    "    # you would add: ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create the preprocessor using ColumnTransformer for regression\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_reg, numerical_features_reg),\n",
    "        ('cat', categorical_transformer_reg, categorical_features_reg)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep other columns not specified (if any)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778088ab",
   "metadata": {},
   "source": [
    "##### 4. Train-Test Split for Each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(X_pos, y_pos, test_size=0.2, random_state=42)\n",
    "X_train_neg, X_test_neg, y_train_neg, y_test_neg = train_test_split(X_neg, y_neg, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n--- Training and Evaluating Regression Models for COVID-positive Deceased Patients ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec0880",
   "metadata": {},
   "source": [
    "##### 5. Regression Models and Hyperparameter Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95549bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn --quiet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define a function to evaluate regression models (reusable for both COVID groups)\n",
    "def evaluate_regression_model(model_name, model, X_train, y_train, X_test, y_test, param_grid={}):\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_reg), # Use the regression preprocessor\n",
    "                               ('regressor', model)])\n",
    "\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    else:\n",
    "        best_model = pipeline\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "    # Plotting actual vs. predicted values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Line of perfect prediction\n",
    "    plt.xlabel(\"Actual Age\")\n",
    "    plt.ylabel(\"Predicted Age\")\n",
    "    plt.title(f\"{model_name} - Actual vs. Predicted Age ({'COVID-Positive' if 'pos' in model_name.lower() else 'COVID-Negative'} Deceased)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # Ensure 'figures' directory exists or create it\n",
    "    # import os\n",
    "    # if not os.path.exists('figures'):\n",
    "    #     os.makedirs('figures')\n",
    "    # plt.savefig(f\"figures/O3_{model_name.lower().replace(' ', '_')}_{'covid_pos' if 'pos' in model_name.lower() else 'covid_neg'}_actual_vs_pred.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return {'model_name': model_name, 'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2,  'best_model': best_model}\n",
    "\n",
    "# --- Train and Evaluate Models for COVID-Positive Deceased ---\n",
    "lin_reg_pos_params = {} # No hyperparameters for basic Linear Regression\n",
    "lin_reg_pos_results = evaluate_regression_model(\"Linear Regression (COVID-Positive)\", LinearRegression(), X_train_pos, y_train_pos, X_test_pos, y_test_pos, lin_reg_pos_params)\n",
    "\n",
    "dt_reg_pos_params = {\n",
    "    'regressor__max_depth': [None, 5, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "dt_reg_pos_results = evaluate_regression_model(\"Decision Tree Regressor (COVID-Positive)\", DecisionTreeRegressor(random_state=42), X_train_pos, y_train_pos, X_test_pos, y_test_pos, dt_reg_pos_params)\n",
    "\n",
    "rf_reg_pos_params = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_leaf': [1, 5]\n",
    "}\n",
    "rf_reg_pos_results = evaluate_regression_model(\"Random Forest Regressor (COVID-Positive)\", RandomForestRegressor(random_state=42), X_train_pos, y_train_pos, X_test_pos, y_test_pos, rf_reg_pos_params)\n",
    "\n",
    "\n",
    "print(\"\\n--- Training and Evaluating Regression Models for COVID-Negative Deceased Patients ---\")\n",
    "\n",
    "# --- Train and Evaluate Models for COVID-Negative Deceased ---\n",
    "lin_reg_neg_params = {}\n",
    "lin_reg_neg_results = evaluate_regression_model(\"Linear Regression (COVID-Negative)\", LinearRegression(), X_train_neg, y_train_neg, X_test_neg, y_test_neg, lin_reg_neg_params)\n",
    "\n",
    "dt_reg_neg_params = {\n",
    "    'regressor__max_depth': [None, 5, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "dt_reg_neg_results = evaluate_regression_model(\"Decision Tree Regressor (COVID-Negative)\", DecisionTreeRegressor(random_state=42), X_train_neg, y_train_neg, X_test_neg, y_test_neg, dt_reg_neg_params)\n",
    "\n",
    "rf_reg_neg_params = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_leaf': [1, 5]\n",
    "}\n",
    "rf_reg_neg_results = evaluate_regression_model(\"Random Forest Regressor (COVID-Negative)\", RandomForestRegressor(random_state=42), X_train_neg, y_train_neg, X_test_neg, y_test_neg, rf_reg_neg_params)\n",
    "\n",
    "# Store all O3 results for easy access in O4\n",
    "o3_results = {\n",
    "    'covid_pos': [lin_reg_pos_results, dt_reg_pos_results, rf_reg_pos_results],\n",
    "    'covid_neg': [lin_reg_neg_results, dt_reg_neg_results, rf_reg_neg_results]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Objective O3 complete. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fab465",
   "metadata": {},
   "source": [
    "## Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Select Best Models from O3 ===\n",
    "best_model_pos = min(o3_results['covid_pos'], key=lambda x: x['rmse'])\n",
    "best_model_neg = min(o3_results['covid_neg'], key=lambda x: x['rmse'])\n",
    "\n",
    "model_pos = best_model_pos['best_model']\n",
    "model_neg = best_model_neg['best_model']\n",
    "\n",
    "# Use the test sets already defined in the notebook\n",
    "# X_test_pos, y_test_pos, X_test_neg, y_test_neg are available\n",
    "\n",
    "# === Evaluation Function ===\n",
    "def evaluate_model(model, X_test, y_test, label, feature_names):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n=== Best Model for {label} ===\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.2f}\")\n",
    "\n",
    "    # Feature Importance\n",
    "    if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "\n",
    "        print(f\"\\nTop Features for {label}:\")\n",
    "        display(importance_df.head(5))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))\n",
    "        plt.title(f'Feature Importance for {label} Model')\n",
    "        plt.show()\n",
    "\n",
    "    # Prediction Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'{label}: Actual vs Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    return model, importance_df if 'importance_df' in locals() else None\n",
    "\n",
    "# Use the correct feature names list\n",
    "feature_names_used = categorical_features_reg\n",
    "\n",
    "# === Evaluate and Show Plots ===\n",
    "model_pos, importance_df_pos = evaluate_model(model_pos, X_test_pos, y_test_pos, \"COVID-Positive\", feature_names_used)\n",
    "model_neg, importance_df_neg = evaluate_model(model_neg, X_test_neg, y_test_neg, \"COVID-Negative\", feature_names_used)\n",
    "\n",
    "# === Save Best Models ===\n",
    "joblib.dump(model_pos, 'best_model_covid_pos.pkl')\n",
    "joblib.dump(model_neg, 'best_model_covid_neg.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0476d77",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The Random Forest regression models were able to predict age of death with the following performance:\n",
    "\n",
    "- **COVID-Positive Deceased**: R² ≈ 12%, MAE ≈ 11,26Y\n",
    "- **COVID-Negative Deceased**: R² ≈ 12%, MAE ≈ 11,26Y\n",
    "\n",
    "These results suggest that age prediction may be Equally accurate in both groups, potentially reflecting age as an indicator of correlation with outcomes for COVID and non-COVID deaths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027524ca",
   "metadata": {},
   "source": [
    "# Objective 4 (O4): Feature Importance for Mortality Prediction\n",
    "\n",
    "In this objective, we identify which features are most influential in predicting mortality. \n",
    "\n",
    "A Random Forest classifier is trained on the full dataset, and the top features are visualized using their importance scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f97527",
   "metadata": {},
   "source": [
    "1: Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Starting Objective O4: Creating a 'Severity Score' ---\")\n",
    "\n",
    "# Work on a copy to avoid affecting global dataset\n",
    "data_o4 = data.copy()\n",
    "\n",
    "# Impute critical columns used for severity definition with most frequent\n",
    "from sklearn.impute import SimpleImputer\n",
    "    # from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "imputer_most_frequent = SimpleImputer(strategy='most_frequent')\n",
    "cols_for_severity_def = ['DIED', 'INTUBED', 'ICU', 'PNEUMONIA', 'HYPERTENSION']\n",
    "for col in cols_for_severity_def:\n",
    "    if col in data_o4.columns:\n",
    "        data_o4[col] = imputer_most_frequent.fit_transform(data_o4[[col]]).flatten()\n",
    "    data_o4[col] = data_o4[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92935dae",
   "metadata": {},
   "source": [
    "#### 1. Feature Importance for O1 (Death Prediction) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c327db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab4bd463",
   "metadata": {},
   "source": [
    "#### 2. Severity Label Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SEVERITY with a placeholder\n",
    "data_o4['SEVERITY'] = -1\n",
    "\n",
    "# High: DIED or (INTUBED and ICU)\n",
    "data_o4.loc[\n",
    "    (data_o4['DIED'] == 1) | ((data_o4['INTUBED'] == 1) & (data_o4['ICU'] == 1)), 'SEVERITY'\n",
    "] = 2\n",
    "\n",
    "# Moderate: if not High, but PNEUMONIA or INTUBED or ICU\n",
    "data_o4.loc[\n",
    "    (data_o4['SEVERITY'] == -1) & (\n",
    "        (data_o4['PNEUMONIA'] == 1) | (data_o4['INTUBED'] == 1) | (data_o4['ICU'] == 1)\n",
    "    ), 'SEVERITY'\n",
    "] = 1\n",
    "\n",
    "# Low: remaining\n",
    "data_o4.loc[data_o4['SEVERITY'] == -1, 'SEVERITY'] = 0\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nDistribution of newly created 'SEVERITY' levels:\")\n",
    "print(data_o4['SEVERITY'].value_counts())\n",
    "print(\"\\nCounts:\")\n",
    "print(data_o4['SEVERITY'].value_counts().sort_index())\n",
    "print(\"\\nPercentages:\")\n",
    "print(data_o4['SEVERITY'].value_counts(normalize=True).sort_index() * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de707d3b",
   "metadata": {},
   "source": [
    "#### 3. Feature Selection and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude columns used to define severity\n",
    "features_for_o4_prediction = [\n",
    "    col for col in features_to_keep if col not in ['DIED', 'INTUBED', 'ICU', 'PNEUMONIA']\n",
    "]\n",
    "\n",
    "X_severity = data_o4[features_for_o4_prediction]\n",
    "y_severity = data_o4['SEVERITY']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_o4, X_test_o4, y_train_o4, y_test_o4 = train_test_split(\n",
    "    X_severity, y_severity, test_size=0.2, random_state=42, stratify=y_severity\n",
    ")\n",
    "\n",
    "\n",
    "# Identify numerical and categorical columns in the reduced feature set\n",
    "numerical_features_o4 = X_train_o4.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features_o4 = X_train_o4.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# New preprocessor just for O4\n",
    "preprocessor_o4 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_o4),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_o4)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\nShape of X_train_o4: {X_train_o4.shape}\")\n",
    "print(f\"Shape of y_train_o4: {y_train_o4.shape}\")\n",
    "print(f\"Shape of X_test_o4: {X_test_o4.shape}\")\n",
    "print(f\"Shape of y_test_o4: {y_test_o4.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5c86e",
   "metadata": {},
   "source": [
    "#### 4. Evaluation Function & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ca257",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model_name, model, X_train, y_train, X_test, y_test, param_grid={}):\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_o4),  \n",
    "    ('classifier', model)\n",
    "    ])\n",
    "\n",
    "\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        best_model = pipeline\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Low', 'Moderate', 'High']))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Low', 'Moderate', 'High'],\n",
    "                yticklabels=['Low', 'Moderate', 'High'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "\n",
    "    if not os.path.exists(\"figures\"):\n",
    "        os.makedirs(\"figures\")\n",
    "    plt.savefig(f\"figures/O4_{model_name.lower().replace(' ', '_')}_confusion_matrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'best_model': best_model,\n",
    "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f1874",
   "metadata": {},
   "source": [
    "#### 5. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c18328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "lr_o4_params = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "lr_o4_results = evaluate_model(\"Logistic Regression (O4)\", LogisticRegression(max_iter=1000, random_state=42),\n",
    "                               X_train_o4, y_train_o4, X_test_o4, y_test_o4, lr_o4_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd391",
   "metadata": {},
   "source": [
    "#### 6. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ed3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_o4_params = {\n",
    "    'classifier__max_depth': [None, 5, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "dt_o4_results = evaluate_model(\"Decision Tree Classifier (O4)\", DecisionTreeClassifier(random_state=42),\n",
    "                               X_train_o4, y_train_o4, X_test_o4, y_test_o4, dt_o4_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041a5c1",
   "metadata": {},
   "source": [
    "#### 7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_o4_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_leaf': [1, 5],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "rf_o4_results = evaluate_model(\"Random Forest Classifier (O4)\", RandomForestClassifier(random_state=42),\n",
    "                               X_train_o4, y_train_o4, X_test_o4, y_test_o4, rf_o4_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62d0b7",
   "metadata": {},
   "source": [
    "#### 8. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn_o4_params = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "    'classifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "knn_o4_results = evaluate_model(\"K-Nearest Neighbors Classifier (O4)\", KNeighborsClassifier(),\n",
    "                                X_train_o4, y_train_o4, X_test_o4, y_test_o4, knn_o4_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eac808",
   "metadata": {},
   "source": [
    "#### 9. Store Results & Wrap Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for summary if needed\n",
    "o4_results = [lr_o4_results, dt_o4_results, rf_o4_results, knn_o4_results]\n",
    "\n",
    "print(\"\\n--- Objective O4 (Severity Score) complete. ---\")\n",
    "\n",
    "# (Optional) Print summary F1 scores\n",
    "for result in o4_results:\n",
    "    score = result['report']['weighted avg']['f1-score']\n",
    "    print(f\"{result['model_name']}: Weighted F1 Score = {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

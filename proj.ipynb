{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30a5c4e",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0dcd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with shape: (100000, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "data = pd.read_csv('data/custom_covid19.csv') \n",
    "print(\"Data loaded with shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159f494",
   "metadata": {},
   "source": [
    "##### 1. Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a401ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DIED'] = data['DATE_DIED'].apply(lambda x: 0 if x == '9999-99-99' else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01577827",
   "metadata": {},
   "source": [
    "##### 2. Mark missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a677a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([97, 98, 99], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38857dd",
   "metadata": {},
   "source": [
    "##### 3. Convert boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed05d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = ['INTUBED', 'PNEUMONIA', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', \n",
    "             'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', \n",
    "             'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU']\n",
    "data[bool_cols] = data[bool_cols].replace(2, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f08925",
   "metadata": {},
   "source": [
    "##### 4. Create COVID status feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda834cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['COVID_POSITIVE'] = data['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bb1ab",
   "metadata": {},
   "source": [
    "##### 5. Define features to keep/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d4c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', \n",
    "                   'INTUBED', 'PNEUMONIA', 'AGE', 'DIABETES', 'COPD',\n",
    "                   'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE',\n",
    "                   'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO',\n",
    "                   'ICU', 'COVID_POSITIVE']\n",
    "\n",
    "# 6. Separate features and target\n",
    "X = data[features_to_keep]\n",
    "y = data['DIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143b8bb",
   "metadata": {},
   "source": [
    "##### 6. Define preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d9882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['AGE']\n",
      "Categorical features: ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'INTUBED', 'PNEUMONIA', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['AGE']\n",
    "categorical_features = [col for col in features_to_keep \n",
    "                       if col not in numeric_features + ['DIED', 'COVID_POSITIVE']]\n",
    "\n",
    "# Numeric pipeline (mean imputation + scaling)\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline (mode imputation)\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combined preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Verification\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293cb08",
   "metadata": {},
   "source": [
    "##### 8. Train-test split\n",
    " \n",
    "Split the data into training and testing sets\n",
    "Stratified split to maintain the same distribution of the target variable in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62d2b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (80000, 19), Test set: (20000, 19)\n",
      "Class distribution (train): DIED\n",
      "0    0.926625\n",
      "1    0.073375\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution (train): {pd.Series(y_train).value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f8b9c",
   "metadata": {},
   "source": [
    "##### 9. Model Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fcfd7e",
   "metadata": {},
   "source": [
    "1. Model Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d12708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll evaluate three baseline classifiers:\n",
    "# 1. Naive Bayes (probabilistic)\n",
    "# 2. K-Nearest Neighbors (instance-based)\n",
    "# 3. SVM with RBF kernel (maximum margin)\n",
    "\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "sns.set_palette(\"husl\")\n",
    "# Ensure 'figures' directory exists\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae8afd",
   "metadata": {},
   "source": [
    "2. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025c3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model and generates report-ready outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - name: str, model name for display\n",
    "    - model: sklearn classifier object\n",
    "    - X_train, X_test, y_train, y_test: training/test data\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing metrics and visualization paths\n",
    "    \"\"\"\n",
    "    # Create pipeline and fit model\n",
    "    clf = make_pipeline(preprocessor, model)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Create classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Confusion matrix heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Survived', 'Died'],\n",
    "                yticklabels=['Survived', 'Died'])\n",
    "    ax1.set_title(f'{name} Confusion Matrix')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('Actual')\n",
    "\n",
    "    # Metrics bar plot\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    scores = [report['weighted avg'][m] for m in metrics]\n",
    "    sns.barplot(x=metrics, y=scores, ax=ax2)\n",
    "    ax2.set_title(f'{name} Performance Metrics')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # Save the figure\n",
    "    fig_path = f'figures/{name.lower().replace(\" \", \"_\")}_performance.png'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Display outputs in the notebook\n",
    "    display(Markdown(f\"## {name} Performance\"))\n",
    "    display(Markdown(\"### Classification Report\"))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    display(Markdown(\"### Confusion Matrix\"))\n",
    "    print(cm)\n",
    "\n",
    "    return {\n",
    "        'model': name,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1': report['weighted avg']['f1-score'],\n",
    "        'figure_path': fig_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5aa60",
   "metadata": {},
   "source": [
    "3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06bf13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Baseline Model Definitions\n",
    "# We select three distinct algorithmic approaches:\n",
    "\n",
    "models = [\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('Support Vector Machine', SVC(kernel='rbf', gamma='scale'))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0ea17",
   "metadata": {},
   "source": [
    "4. Model Evaluation Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3710d9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Naive Bayes Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     18532\n",
      "           1       0.40      0.70      0.51      1468\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.69      0.81      0.73     20000\n",
      "weighted avg       0.93      0.90      0.91     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Confusion Matrix"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16969  1563]\n",
      " [  438  1030]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## K-Nearest Neighbors Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     18532\n",
      "           1       0.62      0.48      0.54      1468\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.79      0.73      0.75     20000\n",
      "weighted avg       0.93      0.94      0.94     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Confusion Matrix"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18100   432]\n",
      " [  770   698]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Support Vector Machine Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Classification Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     18532\n",
      "           1       0.77      0.32      0.46      1468\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.86      0.66      0.71     20000\n",
      "weighted avg       0.94      0.94      0.93     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Confusion Matrix"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18392   140]\n",
      " [  993   475]]\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate All Baseline Models ===\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for name, model in models:\n",
    "    result = evaluate_model(name, model, X_train, X_test, y_train, y_test)\n",
    "    model_results.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8706e",
   "metadata": {},
   "source": [
    "##### 10. Hyperparameter Optimization\n",
    "We implement systematic hyperparameter tuning for all three models using GridSearchCV (exhaustive search) to find optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeef901",
   "metadata": {},
   "source": [
    "A. Naive Bayes (GaussianNB)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9124c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7]  # Note the stepname__param format\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5cab2",
   "metadata": {},
   "source": [
    "B. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f7be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__p': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec82ea",
   "metadata": {},
   "source": [
    "C. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2eaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "    'svc__kernel': ['rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2be46",
   "metadata": {},
   "source": [
    "##### 11. Implementation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57551403",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create pipelines with preprocessing + model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pipeline_nb = \u001b[43mPipeline\u001b[49m([\n\u001b[32m      5\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m      6\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mgaussiannb\u001b[39m\u001b[33m'\u001b[39m, GaussianNB())\n\u001b[32m      7\u001b[39m ])\n\u001b[32m      9\u001b[39m pipeline_knn = Pipeline([\n\u001b[32m     10\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m     11\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mkneighborsclassifier\u001b[39m\u001b[33m'\u001b[39m, KNeighborsClassifier())\n\u001b[32m     12\u001b[39m ])\n\u001b[32m     15\u001b[39m pipeline_svm = Pipeline([\n\u001b[32m     16\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m     17\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33msvc\u001b[39m\u001b[33m'\u001b[39m, SVC())\n\u001b[32m     18\u001b[39m ])\n",
      "\u001b[31mNameError\u001b[39m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create pipelines with preprocessing + model\n",
    "pipeline_nb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gaussiannb', GaussianNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('kneighborsclassifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_nb = GridSearchCV(pipeline_nb, param_grid_nb, cv=5, scoring='f1_weighted')\n",
    "grid_knn = GridSearchCV(pipeline_knn, param_grid_knn, cv=5, scoring='f1_weighted')\n",
    "grid_svm = GridSearchCV(pipeline_svm, param_grid_svm, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Fit models\n",
    "grid_nb.fit(X_train, y_train)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# Less expensive GridsearchCV\n",
    "# param_grid_nb = {}  # No hyperparameters to tune for GaussianNB\n",
    "\n",
    "# param_grid_knn = {\n",
    "#     'kneighborsclassifier__n_neighbors': [3, 5, 7]\n",
    "# }\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svc__C': [0.1, 1, 10],\n",
    "#     'svc__gamma': ['scale', 'auto']\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30a5c4e",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "data = pd.read_csv('data/custom_covid19.csv') \n",
    "print(\"Data loaded with shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159f494",
   "metadata": {},
   "source": [
    "##### 1. Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a401ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DIED'] = data['DATE_DIED'].apply(lambda x: 0 if x == '9999-99-99' else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01577827",
   "metadata": {},
   "source": [
    "##### 2. Mark missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a677a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([97, 98, 99], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38857dd",
   "metadata": {},
   "source": [
    "##### 3. Convert boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = ['INTUBED', 'PNEUMONIA', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', \n",
    "             'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', \n",
    "             'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU']\n",
    "data[bool_cols] = data[bool_cols].replace(2, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f08925",
   "metadata": {},
   "source": [
    "##### 4. Create COVID status feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda834cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['COVID_POSITIVE'] = data['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bb1ab",
   "metadata": {},
   "source": [
    "##### 5. Define features to keep/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', \n",
    "                   'INTUBED', 'PNEUMONIA', 'AGE', 'DIABETES', 'COPD',\n",
    "                   'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE',\n",
    "                   'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO',\n",
    "                   'ICU', 'COVID_POSITIVE']\n",
    "\n",
    "# 6. Separate features and target\n",
    "X = data[features_to_keep]\n",
    "y = data['DIED']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143b8bb",
   "metadata": {},
   "source": [
    "##### 6. Define preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['AGE']\n",
    "categorical_features = [col for col in features_to_keep \n",
    "                       if col not in numeric_features + ['DIED', 'COVID_POSITIVE']]\n",
    "\n",
    "# Numeric pipeline (mean imputation + scaling)\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline (mode imputation)\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combined preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Verification\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293cb08",
   "metadata": {},
   "source": [
    "##### 8. Train-test split\n",
    " \n",
    "Split the data into training and testing sets\n",
    "Stratified split to maintain the same distribution of the target variable in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution (train): {pd.Series(y_train).value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f8b9c",
   "metadata": {},
   "source": [
    "##### 9. Model Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fcfd7e",
   "metadata": {},
   "source": [
    "1. Model Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d12708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll evaluate three baseline classifiers:\n",
    "# 1. Naive Bayes (probabilistic)\n",
    "# 2. K-Nearest Neighbors (instance-based)\n",
    "# 3. SVM with RBF kernel (maximum margin)\n",
    "\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "sns.set_palette(\"husl\")\n",
    "# Ensure 'figures' directory exists\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae8afd",
   "metadata": {},
   "source": [
    "2. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model and generates report-ready outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - name: str, model name for display\n",
    "    - model: sklearn classifier object\n",
    "    - X_train, X_test, y_train, y_test: training/test data\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing metrics and visualization paths\n",
    "    \"\"\"\n",
    "    # Create pipeline and fit model\n",
    "    clf = make_pipeline(preprocessor, model)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Create classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Confusion matrix heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Survived', 'Died'],\n",
    "                yticklabels=['Survived', 'Died'])\n",
    "    ax1.set_title(f'{name} Confusion Matrix')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('Actual')\n",
    "\n",
    "    # Metrics bar plot\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    scores = [report['weighted avg'][m] for m in metrics]\n",
    "    sns.barplot(x=metrics, y=scores, ax=ax2)\n",
    "    ax2.set_title(f'{name} Performance Metrics')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # Save the figure\n",
    "    fig_path = f'figures/{name.lower().replace(\" \", \"_\")}_performance.png'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Display outputs in the notebook\n",
    "    display(Markdown(f\"## {name} Performance\"))\n",
    "    display(Markdown(\"### Classification Report\"))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    display(Markdown(\"### Confusion Matrix\"))\n",
    "    print(cm)\n",
    "\n",
    "    return {\n",
    "        'model': name,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1': report['weighted avg']['f1-score'],\n",
    "        'figure_path': fig_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5aa60",
   "metadata": {},
   "source": [
    "3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Baseline Model Definitions\n",
    "# We select three distinct algorithmic approaches:\n",
    "\n",
    "models = [\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('Support Vector Machine', LinearSVC(random_state=42, class_weight='balanced'))  # Updated\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0ea17",
   "metadata": {},
   "source": [
    "4. Model Evaluation Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate All Baseline Models ===\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for name, model in models:\n",
    "    result = evaluate_model(name, model, X_train, X_test, y_train, y_test)\n",
    "    model_results.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8706e",
   "metadata": {},
   "source": [
    "##### 10. Hyperparameter Optimization\n",
    "We implement systematic hyperparameter tuning for all three models using GridSearchCV (exhaustive search) to find optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeef901",
   "metadata": {},
   "source": [
    "A. Naive Bayes (GaussianNB)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9124c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7]  # Note the stepname__param format\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5cab2",
   "metadata": {},
   "source": [
    "B. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "    'kneighborsclassifier__p': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec82ea",
   "metadata": {},
   "source": [
    "C. Support Vector Machine (SVM) //TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2eaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid_svm = {\n",
    "#     'svc__C': [0.1, 1, 10],\n",
    "#     'svc__gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "#     'svc__kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svc__C': [1, 10],             # instead of a wider range\n",
    "#     'svc__gamma': [0.1, 0.01],     # fewer values\n",
    "#     'svc__kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svc__base_estimator__C': [0.1, 1, 10],  \n",
    "#     'svc__base_estimator__max_iter': [1000, 2000]  \n",
    "# }\n",
    "\n",
    "param_grid_svm = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10]  # Only tuning C for linear SVM\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2be46",
   "metadata": {},
   "source": [
    "##### 11. Implementation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57551403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Create pipelines with preprocessing + model\n",
    "pipeline_nb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gaussiannb', GaussianNB())\n",
    "])\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('kneighborsclassifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svc', LinearSVC(random_state=42, class_weight='balanced'))  # Handles imbalance\n",
    "])\n",
    "\n",
    "# pipeline_svm = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('svc', SVC(probability=True, random_state=42))\n",
    "# ])\n",
    "\n",
    "# GridSearchCV setup with comprehensive parameter grids\n",
    "grid_nb = GridSearchCV(\n",
    "    pipeline_nb, \n",
    "    param_grid_nb, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    pipeline_knn, \n",
    "    param_grid_knn, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm, \n",
    "    param_grid_svm, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit models with timing\n",
    "import time\n",
    "\n",
    "print(\"Optimizing Naive Bayes...\")\n",
    "start = time.time()\n",
    "grid_nb.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "print(\"Optimizing KNN...\")\n",
    "start = time.time()\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "print(\"Optimizing Linear SVC...\")\n",
    "start = time.time()\n",
    "grid_svm.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Naive Bayes best params:\", grid_nb.best_params_)\n",
    "print(\"KNN best params:\", grid_knn.best_params_)\n",
    "print(\"Linear SVC best params:\", grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dd932",
   "metadata": {},
   "source": [
    "##### 12. Valuation using DecisionTree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pipeline_tree = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('decisiontreeclassifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Expanded parameter grid for more thorough search\n",
    "param_grid_tree = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "    'decisiontreeclassifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(\n",
    "    pipeline_tree, \n",
    "    param_grid_tree, \n",
    "    cv=5, \n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Optimizing Decision Tree...\")\n",
    "start = time.time()\n",
    "grid_tree.fit(X_train, y_train)\n",
    "print(f\"Completed in {time.time()-start:.2f}s\\n\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"=== Decision Tree Performance ===\")\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tree, target_names=[\"Alive\", \"Died\"]))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred_tree)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Alive\", \"Died\"],\n",
    "            yticklabels=[\"Alive\", \"Died\"])\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d7bf9",
   "metadata": {},
   "source": [
    "##### 13. Benchmark Models with Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1302aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Model Evaluation Function\n",
    "def evaluate_model(grid, name, X_test, y_test):\n",
    "    y_pred = grid.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Best Params': str(grid.best_params_),\n",
    "        'Train F1': grid.best_score_,\n",
    "        'Test F1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'Test Accuracy': report['accuracy'],\n",
    "        'Test Precision': report['weighted avg']['precision'],\n",
    "        'Test Recall': report['weighted avg']['recall']\n",
    "    }\n",
    "\n",
    "# 2. Evaluate All Models\n",
    "results = [\n",
    "    evaluate_model(grid_nb, \"Naive Bayes\", X_test, y_test),\n",
    "    evaluate_model(grid_knn, \"KNN\", X_test, y_test),\n",
    "    evaluate_model(grid_svm, \"Linear SVC\", X_test, y_test),\n",
    "    evaluate_model(grid_tree, \"Decision Tree\", X_test, y_test)\n",
    "]\n",
    "\n",
    "# 3. Results Comparison\n",
    "results_df = pd.DataFrame(results).sort_values('Test F1', ascending=False)\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "display(results_df.style.background_gradient(cmap='Blues', subset=['Test F1', 'Test Accuracy']))\n",
    "\n",
    "# 4. Feature Importance Analysis (for Tree-based Models)\n",
    "if 'Decision Tree' in results_df['Model'].values:\n",
    "    # Get the trained model and preprocessor\n",
    "    best_tree = grid_tree.best_estimator_.named_steps['decisiontreeclassifier']\n",
    "    \n",
    "    # Get original feature names (before any transformations)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Verify lengths match\n",
    "    if len(feature_names) != len(best_tree.feature_importances_):\n",
    "        print(f\"Warning: Feature count mismatch ({len(feature_names)} vs {len(best_tree.feature_importances_)})\")\n",
    "        feature_names = [f'feature_{i}' for i in range(len(best_tree.feature_importances_))]\n",
    "\n",
    "    # Extract feature names after preprocessing\n",
    "    num_features = numeric_features  # list of numerical feature names\n",
    "    cat_features = categorical_features  # use the original categorical feature names\n",
    "    feature_names = list(num_features) + list(cat_features)\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': best_tree.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Visualize top 10 features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
    "    plt.title('Top 10 Predictive Features for Mortality', fontsize=14)\n",
    "    plt.xlabel('Relative Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation of Key Features\n",
    "    print(\"\\n=== Key Findings from Feature Importance ===\")\n",
    "    print(\"1. PATIENT_TYPE (hospitalization status) is the strongest predictor\")\n",
    "    print(\"2. AGE is the second most important factor\")\n",
    "    print(\"3. INTUBED (ventilator use) and PNEUMONIA are critical clinical indicators\")\n",
    "    print(\"4. Other chronic conditions show relatively small but meaningful impact\")\n",
    "    \n",
    "    # Display full importance table\n",
    "    print(\"\\n=== Complete Feature Importance ===\")\n",
    "    display(importance_df.style.background_gradient(cmap='Blues', subset=['Importance']))\n",
    "\n",
    "# 5. Confusion Matrix for Best Model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = {\n",
    "    \"Naive Bayes\": grid_nb,\n",
    "    \"KNN\": grid_knn,\n",
    "    \"Linear SVC\": grid_svm,\n",
    "    \"Decision Tree\": grid_tree\n",
    "}[best_model_name]\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',\n",
    "            xticklabels=['Survived', 'Died'],\n",
    "            yticklabels=['Survived', 'Died'])\n",
    "plt.title(f'{best_model_name} - Confusion Matrix', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 6. Final Model Selection\n",
    "print(f\"\\n=== Best Performing Model: {best_model_name} ===\")\n",
    "print(\"Considerations for model selection:\")\n",
    "print(\"- Clinical interpretability of decision trees\")\n",
    "print(\"- Importance of understanding feature relationships\")\n",
    "print(\"- Good balance between performance and complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8cfe1",
   "metadata": {},
   "source": [
    "## Objective 2 (O2): Age Prediction\n",
    "**Goal**: Predict the AGE of subjects given other attributes  \n",
    "**Approach**:  \n",
    "- Treat as a regression problem  \n",
    "- Evaluate different regression models  \n",
    "- Optimize hyperparameters  \n",
    "- Analyze feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bf03f",
   "metadata": {},
   "source": [
    "\n",
    "Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1caffa4",
   "metadata": {},
   "source": [
    "##### 1. Prepare Data for Age Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['AGE'].notna()].copy()  # Drop rows with missing AGE\n",
    "\n",
    "# We'll use the same preprocessing pipeline but change the target to AGE\n",
    "features_to_keep = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', \n",
    "                   'INTUBED', 'PNEUMONIA', 'DIABETES', 'COPD',\n",
    "                   'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE',\n",
    "                   'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO',\n",
    "                   'ICU', 'COVID_POSITIVE']\n",
    "\n",
    "X_age = data[features_to_keep]\n",
    "y_age = data['AGE']  # Target is now AGE\n",
    "\n",
    "# Train-test split\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(\n",
    "    X_age, y_age, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab694c43",
   "metadata": {},
   "source": [
    "\n",
    "##### 2. Define Preprocessing Pipeline\n",
    "Similar to O1 but adapted for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "numeric_features_age = []  # No numeric features besides AGE (our target)\n",
    "# if binari Covid\n",
    "# numeric_features_age = ['COVID_POSITIVE']\n",
    "# categorical_features_age = [col for col in features_to_keep if col not in numeric_features_age]\n",
    "categorical_features_age = [col for col in features_to_keep if col != 'COVID_POSITIVE']\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer_age = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer_age = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "preprocessor_age = ColumnTransformer([\n",
    "    ('num', numeric_transformer_age, numeric_features_age),\n",
    "    ('cat', categorical_transformer_age, categorical_features_age)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cf7f6",
   "metadata": {},
   "source": [
    "##### 3. Baseline Regression Mode\n",
    "\n",
    "Let's test three different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to evaluate\n",
    "models_age = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "    ('Support Vector Regression', SVR())\n",
    "]\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models_age:\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor_age),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit and predict\n",
    "    pipeline.fit(X_train_age, y_train_age)\n",
    "    y_pred = pipeline.predict(X_test_age)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test_age, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_age, y_pred))\n",
    "    r2 = r2_score(y_test_age, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33126945",
   "metadata": {},
   "source": [
    "##### 4. Hyperparameter Optimization for Best Model\n",
    "\n",
    "Based on initial results, let's optimize RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad66bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline for optimization\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor_age),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_rf = GridSearchCV(\n",
    "    pipeline_rf,\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Random Forest optimization...\")\n",
    "grid_rf.fit(X_train_age, y_train_age)\n",
    "print(\"Optimization completed!\")\n",
    "\n",
    "# Show best parameters\n",
    "print(\"\\nBest parameters:\", grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774dee5",
   "metadata": {},
   "source": [
    "##### 5. Evaluate Optimized Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861341f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = best_rf.predict(X_test_age)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test_age, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_age, y_pred_rf))\n",
    "r2 = r2_score(y_test_age, y_pred_rf)\n",
    "\n",
    "print(\"\\n=== Optimized Random Forest ===\")\n",
    "print(f\"MAE: {mae:.2f} years\")\n",
    "print(f\"RMSE: {rmse:.2f} years\")\n",
    "print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_age, y_pred_rf, alpha=0.3)\n",
    "plt.plot([y_test_age.min(), y_test_age.max()], \n",
    "         [y_test_age.min(), y_test_age.max()], 'r--')\n",
    "plt.xlabel('Actual Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.title('Actual vs Predicted Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701a28b",
   "metadata": {},
   "source": [
    "##### 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "# Get feature importances\n",
    "if hasattr(best_rf.named_steps['regressor'], 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = categorical_features_age  # Should match the number of importances\n",
    "    \n",
    "    importances = best_rf.named_steps['regressor'].feature_importances_\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title('Feature Importance for Age Prediction')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 5 Features Predicting Age:\")\n",
    "    display(importance_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a35588",
   "metadata": {},
   "source": [
    "##### 7. Final Model Selection and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf, 'best_age_predictor.pkl')\n",
    "print(\"Best age prediction model saved as 'best_age_predictor.pkl'\")\n",
    "# Load the model\n",
    "loaded_model = joblib.load('best_age_predictor.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c5d9e",
   "metadata": {},
   "source": [
    "### Conclusion for O2\n",
    "**Key Findings**:\n",
    "- Best model: Random Forest with MAE of X.XX years\n",
    "- Most important features: Hypertension, Diabities\n",
    "- R2 score of X.XX indicates [good/moderate/poor] explanatory power\n",
    " \n",
    "**Next Steps**:\n",
    "- Proceed to O3 (age prediction for deceased patients)\n",
    "- Consider feature engineering to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92faa128",
   "metadata": {},
   "source": [
    "## Objective 3 (O3): Severity Score Prediction\n",
    "**Goal**: Predict the AGE of subjects given other attributes  \n",
    "**Approach**:  \n",
    "- Treat as a regression problem  \n",
    "- Evaluate different regression models  \n",
    "- Optimize hyperparameters  \n",
    "- Analyze feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9524be",
   "metadata": {},
   "source": [
    "##### 1. Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best models\n",
    "best_nb = grid_nb.best_estimator_\n",
    "best_knn = grid_knn.best_estimator_\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_nb = best_nb.predict(X_test)\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "y_pred_svm = best_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a315a9",
   "metadata": {},
   "source": [
    "##### 2. Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7309d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Naive Bayes Classification Report\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"KNN Classification Report\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print(\"SVM Classification Report\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a075d70",
   "metadata": {},
   "source": [
    "##### 3.  Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "##TODO compare to other coinfusion matrices\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': (best_nb, y_pred_nb),\n",
    "    'KNN': (best_knn, y_pred_knn),\n",
    "    'SVM': (best_svm, y_pred_svm)\n",
    "}\n",
    "\n",
    "for name, (_, y_pred) in models.items():\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues')\n",
    "    disp.ax_.set_title(f'{name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778088ab",
   "metadata": {},
   "source": [
    "##### 5. Comparison Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "summary = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Recall (Weighted)': [],\n",
    "    'F1 Score (Weighted)': []\n",
    "}\n",
    "\n",
    "for name, (_, y_pred) in models.items():\n",
    "    summary['Model'].append(name)\n",
    "    summary['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    summary['Recall (Weighted)'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    summary['F1 Score (Weighted)'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.sort_values(by='F1 Score (Weighted)', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
